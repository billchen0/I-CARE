{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from dataset import ManualFeatureDataset, ManualFeatureDataModule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = Path(\"/media/nvme1/icare-data/6h-features\")\n",
    "labels_csv = Path(\"/home/bc299/icare/patient_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_patient_ids = [dir_.name for dir_ in root_dir.iterdir()]\n",
    "train_ids, temp_ids = train_test_split(all_patient_ids, test_size=0.3, random_state=42)\n",
    "val_ids, test_ids = train_test_split(temp_ids, test_size=2/3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ManualFeatureDataset(root_dir, labels_csv, train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = ManualFeatureDataModule(root_dir=root_dir,\n",
    "                                      labels_csv=labels_csv,\n",
    "                                      batch_size=32)\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import lightning.pytorch as pl\n",
    "from torch.nn.functional import nll_loss\n",
    "from model import BiLSTMClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMClassifierModule(pl.LightningModule):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout, learning_rate):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = BiLSTMClassifier(input_size, hidden_size, num_layers, dropout)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.test_step_outputs = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self.model(x)\n",
    "        loss = nll_loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = (preds == y).float().mean()\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.log(\"train_acc\", acc)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = nll_loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = (preds == y).float().mean()\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True)\n",
    "\n",
    "    # The test step will evaluate the performance for each 6h epoch\n",
    "    # assuming that the 6h epochs are in order and the batch size is 1.\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = nll_loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.test_step_outputs.append({\n",
    "            \"predictions\": preds,\n",
    "            \"labels\": y,\n",
    "            \"batch_idx\": batch_idx\n",
    "        })\n",
    "        return loss\n",
    "    \n",
    "    def on_test_epoch_end(self):\n",
    "        # Create a list of epoch names based on data\n",
    "        epoch_names = [str(x) for x in range(12, 72+1, 6)]\n",
    "        # Store aggregated labels and predictions\n",
    "        aggregated_labels = {name: [] for name in epoch_names}\n",
    "        aggregated_preds = {name: [] for name in epoch_names}\n",
    "        # Aggregate labels and predictions based on batch_idx (6h epochs)\n",
    "        for output in self.test_step_outputs:\n",
    "            batch_idx = output[\"batch_idx\"]\n",
    "            epoch_name = epoch_names[batch_idx]\n",
    "            aggregated_labels[epoch_name].extend(output[\"labels\"].cpu().numpy())\n",
    "            aggregated_preds[epoch_name].extend(output[\"predictions\"].cpu().numpy())\n",
    "        # Compute and log metrics for each 6h epoch\n",
    "        for epoch_name in epoch_names:\n",
    "            labels = aggregated_labels[epoch_name]\n",
    "            preds = aggregated_preds[epoch_name]\n",
    "            acc = accuracy_score(labels, preds)\n",
    "            self.log(f\"test_acc_{epoch_name}\", acc)\n",
    "        # Free memory\n",
    "        self.test_step_outputs.clear()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbillchen0011\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20230914_000037-2h65ztvk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/billchen0011/test-project/runs/2h65ztvk' target=\"_blank\">test-by-epoch</a></strong> to <a href='https://wandb.ai/billchen0011/test-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/billchen0011/test-project' target=\"_blank\">https://wandb.ai/billchen0011/test-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/billchen0011/test-project/runs/2h65ztvk' target=\"_blank\">https://wandb.ai/billchen0011/test-project/runs/2h65ztvk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from lightning.pytorch import Trainer\n",
    "\n",
    "data_module = ManualFeatureDataModule(root_dir, labels_csv, batch_size=32)\n",
    "model = BiLSTMClassifierModule(input_size=8, hidden_size=128, num_layers=4, dropout=0.5, learning_rate=1e-5)\n",
    "logger = WandbLogger(project=\"test-project\", name=\"test-by-epoch\")\n",
    "trainer = Trainer(max_epochs=50, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type             | Params\n",
      "-------------------------------------------\n",
      "0 | model | BiLSTMClassifier | 1.3 M \n",
      "-------------------------------------------\n",
      "1.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 M     Total params\n",
      "5.310     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bc299/miniconda3/envs/icare/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/bc299/miniconda3/envs/icare/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 123/123 [00:00<00:00, 169.26it/s, v_num=ztvk, val_loss=0.629, val_acc=0.624]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 123/123 [00:00<00:00, 165.23it/s, v_num=ztvk, val_loss=0.629, val_acc=0.624]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/bc299/miniconda3/envs/icare/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 320.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test_acc_12        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6764705882352942     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test_acc_18        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5980392156862745     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test_acc_24        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6372549019607843     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test_acc_30        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6764705882352942     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test_acc_36        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6078431372549019     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test_acc_42        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5686274509803921     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test_acc_48        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5490196078431373     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test_acc_54        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5392156862745098     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test_acc_60        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5490196078431373     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test_acc_66        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5784313725490197     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test_acc_72        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5980392156862745     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test_acc_12       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6764705882352942    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test_acc_18       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5980392156862745    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test_acc_24       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6372549019607843    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test_acc_30       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6764705882352942    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test_acc_36       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6078431372549019    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test_acc_42       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5686274509803921    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test_acc_48       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5490196078431373    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test_acc_54       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5392156862745098    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test_acc_60       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5490196078431373    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test_acc_66       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5784313725490197    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test_acc_72       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5980392156862745    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_acc_12': 0.6764705882352942,\n",
       "  'test_acc_18': 0.5980392156862745,\n",
       "  'test_acc_24': 0.6372549019607843,\n",
       "  'test_acc_30': 0.6764705882352942,\n",
       "  'test_acc_36': 0.6078431372549019,\n",
       "  'test_acc_42': 0.5686274509803921,\n",
       "  'test_acc_48': 0.5490196078431373,\n",
       "  'test_acc_54': 0.5392156862745098,\n",
       "  'test_acc_60': 0.5490196078431373,\n",
       "  'test_acc_66': 0.5784313725490197,\n",
       "  'test_acc_72': 0.5980392156862745}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icare",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
