{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from dataset import ManualFeatureDataset, ManualFeatureDataModule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = Path(\"/media/nvme1/icare-data/6h-features\")\n",
    "labels_csv = Path(\"/home/bc299/icare/patient_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_patient_ids = [dir_.name for dir_ in root_dir.iterdir()]\n",
    "train_ids, temp_ids = train_test_split(all_patient_ids, test_size=0.3, random_state=42)\n",
    "val_ids, test_ids = train_test_split(temp_ids, test_size=2/3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ManualFeatureDataset(root_dir, labels_csv, train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = ManualFeatureDataModule(root_dir=root_dir,\n",
    "                                      labels_csv=labels_csv,\n",
    "                                      batch_size=32)\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 8, 144])\n",
      "torch.Size([32, 8, 144])\n",
      "torch.Size([32, 8, 144])\n",
      "torch.Size([32, 8, 144])\n",
      "torch.Size([32, 8, 144])\n",
      "torch.Size([32, 8, 144])\n",
      "torch.Size([32, 8, 144])\n",
      "torch.Size([32, 8, 144])\n",
      "torch.Size([32, 8, 144])\n",
      "torch.Size([32, 8, 144])\n",
      "torch.Size([32, 8, 144])\n",
      "torch.Size([32, 8, 144])\n",
      "torch.Size([32, 8, 144])\n",
      "torch.Size([32, 8, 144])\n",
      "torch.Size([32, 8, 144])\n",
      "torch.Size([32, 8, 144])\n",
      "torch.Size([32, 8, 144])\n",
      "torch.Size([32, 8, 144])\n",
      "torch.Size([32, 8, 144])\n",
      "torch.Size([32, 8, 144])\n",
      "torch.Size([32, 8, 144])\n",
      "torch.Size([32, 8, 144])\n",
      "torch.Size([32, 8, 144])\n",
      "torch.Size([32, 8, 144])\n",
      "torch.Size([32, 8, 144])\n",
      "torch.Size([32, 8, 144])\n",
      "torch.Size([32, 8, 144])\n",
      "torch.Size([32, 8, 144])\n",
      "torch.Size([32, 8, 144])\n",
      "torch.Size([32, 8, 144])\n",
      "torch.Size([32, 8, 144])\n",
      "torch.Size([32, 8, 144])\n",
      "torch.Size([32, 8, 144])\n",
      "torch.Size([32, 8, 144])\n",
      "torch.Size([32, 8, 144])\n",
      "torch.Size([2, 8, 144])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (x, y) in enumerate(data_module.test_dataloader()):\n",
    "    print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import lightning.pytorch as pl\n",
    "from torch.optim import Adam\n",
    "from torch.nn.functional import nll_loss\n",
    "from model import BiLSTMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMClassifierModule(pl.LightningModule):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout, learning_rate):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = BiLSTMClassifier(input_size, hidden_size, num_layers, dropout)\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self.model(x)\n",
    "        loss = nll_loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = (preds == y).float().mean()\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.log(\"train_acc\", acc)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = nll_loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = (preds == y).float().mean()\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate, weight_decay=0.01)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from lightning.pytorch import Trainer\n",
    "\n",
    "data_module = ManualFeatureDataModule(root_dir, labels_csv, batch_size=32)\n",
    "model = BiLSTMClassifierModule(input_size=8, hidden_size=128, num_layers=4, dropout=0.5, learning_rate=1e-5)\n",
    "logger = TensorBoardLogger(\"tb_logs\", name=\"test_classifier\")\n",
    "trainer = Trainer(max_epochs=50, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type             | Params\n",
      "-------------------------------------------\n",
      "0 | model | BiLSTMClassifier | 1.3 M \n",
      "-------------------------------------------\n",
      "1.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 M     Total params\n",
      "5.310     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bc299/miniconda3/envs/icare/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/bc299/miniconda3/envs/icare/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 123/123 [00:00<00:00, 171.26it/s, v_num=11, val_loss=0.665, val_acc=0.627]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 123/123 [00:00<00:00, 167.84it/s, v_num=11, val_loss=0.665, val_acc=0.627]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icare",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
